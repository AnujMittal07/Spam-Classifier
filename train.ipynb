{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../inputs/spam_data.csv\",encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['v1','v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v1'] = df['v1'].apply(lambda x: 1 if x=='spam' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v1'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = ' '.join(list(df[df['v1']==1]['v2']))\n",
    "spam_wc = WordCloud(width=500,height=500).generate(spam_words)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(spam_wc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_spam_words = ' '.join(list(df[df['v1']==0]['v2']))\n",
    "spam_wc = WordCloud(width=500,height=500).generate(not_spam_words)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(spam_wc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NO UPSAMPLING OR DOWNSAMPLING, PREPROCESSING + BOW + NB + CV (GRID, RANDOM, BAYESIAN OPTIMISATION) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../inputs/spam_data.csv\",encoding='ISO-8859-1')\n",
    "df = df[['v1','v2']]\n",
    "df['v1'] = df['v1'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "df.columns = ['label','document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_train = df.loc[:4500,:].reset_index(drop=True)\n",
    "df_test = df.loc[4500:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING STEPS:<BR> 1) REMOVE ANYTHING THAT IS NOT A-Z AND 0-9<BR>\n",
    "                     2) LOWER CASE<BR>\n",
    "                     3) STOP WORDS REMOVAL<BR>\n",
    "                     4) STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean_text(sentence):\n",
    "    final_string = ''\n",
    "    sentence = re.sub(f'[{re.escape(string.punctuation)}]','',' '.join(word_tokenize(sentence))).lower()\n",
    "    sentence = ' '.join(word_tokenize(sentence))\n",
    "    for word in sentence.split():\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in stop:\n",
    "            final_string = final_string + word +' '\n",
    "    return final_string.rstrip().lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['document'] = df_train['document'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['kfold'] = -1\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for fold_,(t_,v_) in enumerate(kf.split(X=df_train,y=df_train['label'])):\n",
    "    df_train.loc[v_,'kfold'] = fold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    train = df_train[df_train['kfold']!=fold].reset_index(drop=True)\n",
    "    valid = df_train[df_train['kfold']==fold].reset_index(drop=True)\n",
    "    \n",
    "    bow = CountVectorizer(binary=True)\n",
    "    bow.fit(train['document'])\n",
    "    \n",
    "    x_train = bow.transform(train['document'])\n",
    "    y_train = train['label']\n",
    "    \n",
    "    x_valid = bow.transform(valid['document'])\n",
    "    \n",
    "    NB = naive_bayes.MultinomialNB()\n",
    "    NB.fit(x_train,y_train)\n",
    "    \n",
    "    preds = NB.predict(x_valid)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(valid['label'],preds)\n",
    "    \n",
    "    print(f'For fold = {fold}, AUC = {auc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(binary=True)\n",
    "bow.fit(df_train['document'])\n",
    "x_train = bow.transform(df_train['document'])\n",
    "y_train = df_train['label']\n",
    "\n",
    "df_test['document'] = df_test['document'].apply(lambda x: clean_text(x))\n",
    "\n",
    "x_test = bow.transform(df_test['document'])\n",
    "y_test = df_test['label']\n",
    "\n",
    "NB = naive_bayes.MultinomialNB()\n",
    "NB.fit(x_train,y_train)\n",
    "\n",
    "preds = NB.predict(x_test)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test,preds)\n",
    "\n",
    "print(f'AUC = {auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCH\n",
    "X = df_train['document']\n",
    "X = X.apply(clean_text)\n",
    "bow = CountVectorizer(binary=True)\n",
    "bow.fit(X)\n",
    "X = bow.transform(X)\n",
    "y = df_train['label']\n",
    "\n",
    "classifier = naive_bayes.MultinomialNB()\n",
    "param_grid = {'alpha':[0.0001,0.001,0.01,0.1,1,10,100,1000]}\n",
    "model = GridSearchCV(estimator = classifier, param_grid=param_grid,verbose=10,scoring='roc_auc',cv=5)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['document']\n",
    "X_test = X_test.apply(clean_text)\n",
    "X_test = bow.transform(X_test)\n",
    "y_test = df_test['label']\n",
    "\n",
    "NB = naive_bayes.MultinomialNB(alpha=0.1)\n",
    "NB.fit(X,y)\n",
    "\n",
    "preds = NB.predict(X_test)\n",
    "\n",
    "print(metrics.roc_auc_score(y_test,preds))\n",
    "print(metrics.precision_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = NB.predict(X)\n",
    "\n",
    "print(metrics.roc_auc_score(y,preds))\n",
    "print(metrics.precision_score(y,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['document']\n",
    "X_test = X_test.apply(clean_text)\n",
    "X_test = bow.transform(X_test)\n",
    "y_test = df_test['label']\n",
    "\n",
    "train_auc = []\n",
    "test_auc = []\n",
    "for alpha in [0.0001,0.001,0.01,0.1,1,10,100,1000]:\n",
    "    NB = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    NB.fit(X,y)\n",
    "\n",
    "    preds_test = NB.predict(X_test)\n",
    "    preds_train = NB.predict(X)\n",
    "    auc_test = metrics.roc_auc_score(y_test,preds_test)\n",
    "    auc_train = metrics.roc_auc_score(y,preds_train)\n",
    "    \n",
    "    train_auc.append(auc_train)\n",
    "    test_auc.append(auc_test)\n",
    "    #print('ALPHA: '+ str(alpha) + ' TRAINING AUC: '+ str(round(auc_train,2))+' TEST AUC: '+ str(round(auc_test,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0001,0.001,0.01,0.1,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'alpha':alpha,'train_auc':train_auc,'test_auc':test_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(7,7))\n",
    "temp_df.plot(x = 'alpha',y='train_auc',ax=ax)\n",
    "temp_df.plot(x = 'alpha',y='test_auc',ax=ax)\n",
    "#plt.xlim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS TIME WE WILL OVERSAMPLE THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../inputs/spam_data.csv\",encoding='ISO-8859-1')\n",
    "df = df[['v1','v2']]\n",
    "df['v1'] = df['v1'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "df.columns = ['label','document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           document\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df_train = df.loc[:4500,:].reset_index(drop=True)\n",
    "df_test = df.loc[4500:,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.862253\n",
       "1    0.137747\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_spam = df_train[df_train['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_not_spam = df_train[df_train['label']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3881, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_not_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_spam = df_train_spam.sample(df_train_not_spam.shape[0],replace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3881, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train_spam,df_train_not_spam]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean_text(sentence):\n",
    "    final_string = ''\n",
    "    sentence = re.sub(f'[{re.escape(string.punctuation)}]','',' '.join(word_tokenize(sentence))).lower()\n",
    "    sentence = ' '.join(word_tokenize(sentence))\n",
    "    for word in sentence.split():\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in stop:\n",
    "            final_string = final_string + word +' '\n",
    "    return final_string.rstrip().lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['document'] = df_train['document'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>urgent call 09061749602 landlin complimentari ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hot live fantasi call 08707500020 20p per min ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ãã come lt 25 n pass lar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>wonder okor great month cherish guy wish well ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hot live fantasi call 08707500020 20p per min ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           document\n",
       "0      1  urgent call 09061749602 landlin complimentari ...\n",
       "1      1  hot live fantasi call 08707500020 20p per min ...\n",
       "2      0                         ãã come lt 25 n pass lar\n",
       "3      0  wonder okor great month cherish guy wish well ...\n",
       "4      1  hot live fantasi call 08707500020 20p per min ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "bow.fit(df_train['document'])\n",
    "X = bow.transform(df_train['document'])\n",
    "y = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5; 1/6] START alpha=0.01..................................................\n",
      "[CV 1/5; 1/6] END ...................alpha=0.01;, score=1.000 total time=   0.0s\n",
      "[CV 2/5; 1/6] START alpha=0.01..................................................\n",
      "[CV 2/5; 1/6] END ...................alpha=0.01;, score=0.999 total time=   0.0s\n",
      "[CV 3/5; 1/6] START alpha=0.01..................................................\n",
      "[CV 3/5; 1/6] END ...................alpha=0.01;, score=0.998 total time=   0.0s\n",
      "[CV 4/5; 1/6] START alpha=0.01..................................................\n",
      "[CV 4/5; 1/6] END ...................alpha=0.01;, score=0.999 total time=   0.0s\n",
      "[CV 5/5; 1/6] START alpha=0.01..................................................\n",
      "[CV 5/5; 1/6] END ...................alpha=0.01;, score=0.998 total time=   0.0s\n",
      "[CV 1/5; 2/6] START alpha=0.1...................................................\n",
      "[CV 1/5; 2/6] END ....................alpha=0.1;, score=0.999 total time=   0.0s\n",
      "[CV 2/5; 2/6] START alpha=0.1...................................................\n",
      "[CV 2/5; 2/6] END ....................alpha=0.1;, score=0.999 total time=   0.0s\n",
      "[CV 3/5; 2/6] START alpha=0.1...................................................\n",
      "[CV 3/5; 2/6] END ....................alpha=0.1;, score=0.998 total time=   0.0s\n",
      "[CV 4/5; 2/6] START alpha=0.1...................................................\n",
      "[CV 4/5; 2/6] END ....................alpha=0.1;, score=0.998 total time=   0.0s\n",
      "[CV 5/5; 2/6] START alpha=0.1...................................................\n",
      "[CV 5/5; 2/6] END ....................alpha=0.1;, score=0.997 total time=   0.0s\n",
      "[CV 1/5; 3/6] START alpha=1.....................................................\n",
      "[CV 1/5; 3/6] END ......................alpha=1;, score=0.998 total time=   0.0s\n",
      "[CV 2/5; 3/6] START alpha=1.....................................................\n",
      "[CV 2/5; 3/6] END ......................alpha=1;, score=0.995 total time=   0.0s\n",
      "[CV 3/5; 3/6] START alpha=1.....................................................\n",
      "[CV 3/5; 3/6] END ......................alpha=1;, score=0.995 total time=   0.0s\n",
      "[CV 4/5; 3/6] START alpha=1.....................................................\n",
      "[CV 4/5; 3/6] END ......................alpha=1;, score=0.994 total time=   0.0s\n",
      "[CV 5/5; 3/6] START alpha=1.....................................................\n",
      "[CV 5/5; 3/6] END ......................alpha=1;, score=0.996 total time=   0.0s\n",
      "[CV 1/5; 4/6] START alpha=10....................................................\n",
      "[CV 1/5; 4/6] END .....................alpha=10;, score=0.995 total time=   0.0s\n",
      "[CV 2/5; 4/6] START alpha=10....................................................\n",
      "[CV 2/5; 4/6] END .....................alpha=10;, score=0.991 total time=   0.0s\n",
      "[CV 3/5; 4/6] START alpha=10....................................................\n",
      "[CV 3/5; 4/6] END .....................alpha=10;, score=0.993 total time=   0.0s\n",
      "[CV 4/5; 4/6] START alpha=10....................................................\n",
      "[CV 4/5; 4/6] END .....................alpha=10;, score=0.990 total time=   0.0s\n",
      "[CV 5/5; 4/6] START alpha=10....................................................\n",
      "[CV 5/5; 4/6] END .....................alpha=10;, score=0.994 total time=   0.0s\n",
      "[CV 1/5; 5/6] START alpha=100...................................................\n",
      "[CV 1/5; 5/6] END ....................alpha=100;, score=0.992 total time=   0.0s\n",
      "[CV 2/5; 5/6] START alpha=100...................................................\n",
      "[CV 2/5; 5/6] END ....................alpha=100;, score=0.987 total time=   0.0s\n",
      "[CV 3/5; 5/6] START alpha=100...................................................\n",
      "[CV 3/5; 5/6] END ....................alpha=100;, score=0.989 total time=   0.0s\n",
      "[CV 4/5; 5/6] START alpha=100...................................................\n",
      "[CV 4/5; 5/6] END ....................alpha=100;, score=0.984 total time=   0.0s\n",
      "[CV 5/5; 5/6] START alpha=100...................................................\n",
      "[CV 5/5; 5/6] END ....................alpha=100;, score=0.991 total time=   0.0s\n",
      "[CV 1/5; 6/6] START alpha=1000..................................................\n",
      "[CV 1/5; 6/6] END ...................alpha=1000;, score=0.986 total time=   0.0s\n",
      "[CV 2/5; 6/6] START alpha=1000..................................................\n",
      "[CV 2/5; 6/6] END ...................alpha=1000;, score=0.979 total time=   0.0s\n",
      "[CV 3/5; 6/6] START alpha=1000..................................................\n",
      "[CV 3/5; 6/6] END ...................alpha=1000;, score=0.982 total time=   0.0s\n",
      "[CV 4/5; 6/6] START alpha=1000..................................................\n",
      "[CV 4/5; 6/6] END ...................alpha=1000;, score=0.971 total time=   0.0s\n",
      "[CV 5/5; 6/6] START alpha=1000..................................................\n",
      "[CV 5/5; 6/6] END ...................alpha=1000;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = naive_bayes.MultinomialNB()\n",
    "params_grid = {'alpha':[0.01,0.1,1,10,100,1000]}\n",
    "model = GridSearchCV(estimator=NB,param_grid=params_grid,cv=5,scoring='roc_auc',verbose=10)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988055805813405"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['document'] = df_test['document'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Alpha = 0.0001, train auc = 0.99 and test auc = 0.94\n"
     ]
    }
   ],
   "source": [
    "X_test = bow.transform(df_test['document'])\n",
    "y_test = df_test['label']\n",
    "\n",
    "NB = naive_bayes.MultinomialNB(alpha=0.01)\n",
    "NB.fit(X,y)\n",
    "\n",
    "train_auc = round(metrics.roc_auc_score(y,NB.predict(X)),2)\n",
    "test_auc = round(metrics.roc_auc_score(y_test,NB.predict(X_test)),2)\n",
    "\n",
    "print(f'For Alpha = 0.01, train auc = {train_auc} and test auc = {test_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
